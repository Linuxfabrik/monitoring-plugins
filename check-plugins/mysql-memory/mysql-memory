#!/usr/bin/env python3
# -*- coding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see LICENSE file.

# https://github.com/Linuxfabrik/monitoring-plugins/blob/main/CONTRIBUTING.rst

"""See the check's README for more details.
"""

import argparse  # pylint: disable=C0413
import os  # pylint: disable=C0413
import sys  # pylint: disable=C0413

import lib.base  # pylint: disable=C0413
import lib.db_mysql  # pylint: disable=C0413
import lib.human  # pylint: disable=C0413
import lib.version  # pylint: disable=C0413
from lib.globals import (STATE_OK, STATE_UNKNOWN,  # pylint: disable=C0413
                          STATE_WARN)

try:
    import psutil  # pylint: disable=C0413
    HAVE_PSUTIL = True
except ImportError:
    HAVE_PSUTIL = False


__author__ = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2023091801'

DESCRIPTION = """Checks memory metrics for MySQL/MariaDB."""

DEFAULT_DEFAULTS_FILE = '/var/spool/icinga2/.my.cnf'
DEFAULT_DEFAULTS_GROUP = 'client'
DEFAULT_TIMEOUT = 3


def parse_args():
    """Parse command line arguments using argparse.
    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument(
        '-V', '--version',
        action='version',
        version='{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
    )

    parser.add_argument(
        '--always-ok',
        help='Always returns OK.',
        dest='ALWAYS_OK',
        action='store_true',
        default=False,
    )

    parser.add_argument(
        '--defaults-file',
        help='Specifies a cnf file to read parameters like user, host and password from '
             '(instead of specifying them on the command line), '
             'for example `/var/spool/icinga2/.my.cnf`. Default: %(default)s',
        dest='DEFAULTS_FILE',
        default=DEFAULT_DEFAULTS_FILE,
    )

    parser.add_argument(
        '--defaults-group',
        help='Group/section to read from in the cnf file. Default: %(default)s',
        dest='DEFAULTS_GROUP',
        default=DEFAULT_DEFAULTS_GROUP,
    )

    parser.add_argument(
        '--timeout',
        help='Network timeout in seconds. Default: %(default)s (seconds)',
        dest='TIMEOUT',
        type=int,
        default=DEFAULT_TIMEOUT,
    )

    return parser.parse_args()


def get_vars(conn):
    # Do not implement `get_all_vars()`, just fetch the ones we need for this check.
    # Without the GLOBAL modifier, SHOW VARIABLES displays the values that are used for
    # the current connection to MariaDB.
    sql = """
        show global variables
        where variable_name like 'aria_pagecache_buffer_size'
            or variable_name like 'innodb_additional_mem_pool_size'
            or variable_name like 'innodb_buffer_pool_size'
            or variable_name like 'innodb_log_buffer_size'
            or variable_name like 'join_buffer_size'
            or variable_name like 'key_buffer_size'
            or variable_name like 'max_allowed_packet'
            or variable_name like 'max_connections'
            or variable_name like 'max_heap_table_size'
            or variable_name like 'performance_schema'
            or variable_name like 'query_cache_size'
            or variable_name like 'read_buffer_size'
            or variable_name like 'read_rnd_buffer_size'
            or variable_name like 'sort_buffer_size'
            or variable_name like 'thread_stack'
            or variable_name like 'tmp_table_size'
            ;
          """
    return lib.base.coe(lib.db_mysql.select(conn, sql))


def get_status(conn):
    # Do not implement `get_all_vars()`, just fetch the ones we need for this check.
    # Without the GLOBAL modifier, SHOW STATUS displays the values that are used for
    # the current connection to MariaDB.
    sql = """
        show global status
        where variable_name like 'Max_used_connections'
            ;
          """
    return lib.base.coe(lib.db_mysql.select(conn, sql))


def get_pf_memory(conn, myvar):
    # get memory usage from Performance Schema
    if not myvar.get('performance_schema', 0):
        return 0
    if myvar['performance_schema'] == 'OFF':
        return 0

    sql = 'show engine performance_schema status;'
    infoPFSMemory = lib.base.coe(lib.db_mysql.select(conn, sql))
    if len(infoPFSMemory) == 0:
        return 0
    for item in infoPFSMemory:
        if item['Type'] == 'performance_schema' and item['Name'].startswith('memory'):
            return int(item['Status'])
            break
    return 0


def get_other_process_memory():
    if not HAVE_PSUTIL:
        return 0
    totalMemOther = 0
    if lib.version.version(psutil.__version__) >= lib.version.version('5.3.0'):
        try:
            for p in psutil.process_iter(attrs=['name', 'cmdline', 'memory_info']):
                if not p.info['cmdline']:
                    continue
                cmdline = ' '.join(p.info['cmdline'])
                if not cmdline.strip():
                    continue
                if 'PID' in cmdline:
                    continue
                if 'mysqld' in cmdline:
                    continue
                if 'mariadbd' in cmdline:
                    continue
                if 'systemd' in cmdline:
                    continue
                if '[' in cmdline or ']' in cmdline:
                    continue
                if cmdline.startswith(' '):
                    continue
                totalMemOther += p.info['memory_info'].rss
        except psutil.NoSuchProcess:
            pass
    else:
        try:
            for p in [x.as_dict(attrs=['name', 'cmdline', 'memory_info']) for x in psutil.process_iter()]:
                if not cmdline.strip():
                    continue
                if 'PID' in cmdline:
                    continue
                if 'mysqld' in cmdline:
                    continue
                if 'mariadbd' in cmdline:
                    continue
                if 'systemd' in cmdline:
                    continue
                if '[' in cmdline or ']' in cmdline:
                    continue
                if cmdline.startswith(' '):
                    continue
                totalMemOther += p.info['memory_info'].rss
        except psutil.NoSuchProcess:
            pass
    return totalMemOther


def main():
    """The main function. Hier spielt die Musik.
    """

    # logic taken from mysqltuner.pl:mysql_stats(), section # Memory usage, v1.9.8
    # including variable names

    # parse the command line, exit with UNKNOWN if it fails
    try:
        args = parse_args()
    except SystemExit:
        sys.exit(STATE_UNKNOWN)

    mysql_connection = {
        'defaults_file':  args.DEFAULTS_FILE,
        'defaults_group': args.DEFAULTS_GROUP,
        'timeout':        args.TIMEOUT,
    }
    conn = lib.base.coe(lib.db_mysql.connect(mysql_connection))
    lib.base.coe(lib.db_mysql.check_select_privileges(conn))

    myvar = lib.db_mysql.lod2dict(get_vars(conn))
    mystat = lib.db_mysql.lod2dict(get_status(conn))

    # init some vars
    msg = ''
    state = STATE_OK
    perfdata = ''

    # calculations
    mycalc = {}
    mycalc['max_tmp_table_size'] = max(int(myvar['max_heap_table_size']), int(myvar['tmp_table_size']))
    mycalc['server_buffers'] = int(myvar['key_buffer_size']) + mycalc['max_tmp_table_size']
    mycalc['server_buffers'] += int(myvar.get('innodb_buffer_pool_size', 0))
    mycalc['server_buffers'] += int(myvar.get('innodb_additional_mem_pool_size', 0))
    mycalc['server_buffers'] += int(myvar.get('innodb_log_buffer_size', 0))
    mycalc['server_buffers'] += int(myvar.get('query_cache_size', 0))
    mycalc['server_buffers'] += int(myvar.get('aria_pagecache_buffer_size', 0))
    mycalc['per_thread_buffers'] = int(myvar['read_buffer_size'])
    mycalc['per_thread_buffers'] += int(myvar['read_rnd_buffer_size'])
    mycalc['per_thread_buffers'] += int(myvar['sort_buffer_size'])
    mycalc['per_thread_buffers'] += int(myvar['thread_stack'])
    mycalc['per_thread_buffers'] += int(myvar['max_allowed_packet'])
    mycalc['per_thread_buffers'] += int(myvar['join_buffer_size'])
    mycalc['max_total_per_thread_buffers'] = mycalc['per_thread_buffers'] * int(mystat['Max_used_connections'])
    mycalc['total_per_thread_buffers'] = mycalc['per_thread_buffers'] * int(myvar['max_connections'])

    # Global memory
    # Max used memory is memory used by MySQL based on Max_used_connections
    # This is the max memory used theoretically calculated with the max concurrent connection number reached by mysql
    mycalc['pf_memory'] = get_pf_memory(conn, myvar)
    mycalc['max_used_memory'] = mycalc['server_buffers'] + mycalc['max_total_per_thread_buffers'] + mycalc['pf_memory']
    mycalc['max_peak_memory'] = mycalc['server_buffers'] + mycalc['total_per_thread_buffers'] + mycalc['pf_memory']
    physical_memory = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')
    mycalc['pct_max_used_memory'] = round(mycalc['max_used_memory'] / physical_memory * 100, 1)
    mycalc['pct_max_physical_memory'] = round(mycalc['max_peak_memory'] / physical_memory * 100, 1)

    lib.db_mysql.close(conn)

    if not lib.base.X86_64 and mycalc['max_used_memory'] > 2 * 1024 * 1024 * 1024:
        mem1_state = STATE_WARN
        msg += 'Allocating > 2GB RAM on 32-bit systems can cause system instability. '
    elif mycalc['pct_max_used_memory'] > 85:
        mem1_state = STATE_WARN
    else:
        mem1_state = STATE_OK
    state = lib.base.get_worst(state, mem1_state)
    msg += '{}% - total: {}, used: {}{}. '.format(
        mycalc['pct_max_used_memory'],
        lib.human.bytes2human(physical_memory),
        lib.human.bytes2human(mycalc['max_used_memory']),
        lib.base.state2str(mem1_state, prefix=' '),
    )

    msg += 'Maximum possible memory usage is {}% (possible peak: {}). '.format(
        mycalc['pct_max_physical_memory'],
        lib.human.bytes2human(mycalc['max_peak_memory']),
    )
    if mycalc['pct_max_physical_memory'] > 85:
        msg += 'Reduce your overall MySQL memory footprint for system stability. '

    if physical_memory < mycalc['max_peak_memory'] + get_other_process_memory():
        mem2_state = STATE_WARN
        state = lib.base.get_worst(state, mem2_state)
        msg += 'Overall possible memory usage with other processes will exceed memory{}. Dedicate this server to your database for highest performance.'.format(
            lib.base.state2str(mem2_state, prefix=' '),
        )

    # be nice and print the calculation
    msg += '\n\nCalculations:\n'
    msg += '* Memory usage according to Performance Schema: pfm = {}\n'.format(
        lib.human.bytes2human(mycalc['pf_memory']),
    )
    msg += '* Server Buffers: sb = {}\n'.format(
        lib.human.bytes2human(mycalc['server_buffers']),
    )
    msg += '* Max Total per Thread Buffers: mtptb = {}\n'.format(
        lib.human.bytes2human(mycalc['max_total_per_thread_buffers']),
    )
    msg += '* Total per Thread Buffers: tptb = {}\n'.format(
        lib.human.bytes2human(mycalc['total_per_thread_buffers']),
    )
    msg += '* Max Used Memory: mum = sb + mtptb + pfm = {} + {} + {} = {}\n'.format(
        lib.human.bytes2human(mycalc['server_buffers']),
        lib.human.bytes2human(mycalc['max_total_per_thread_buffers']),
        lib.human.bytes2human(mycalc['pf_memory']),
        lib.human.bytes2human(mycalc['max_used_memory']),
    )
    msg += '* Possible Peak Memory: ppm = sb + tptb + pfm = {} + {} + {} = {}\n'.format(
        lib.human.bytes2human(mycalc['server_buffers']),
        lib.human.bytes2human(mycalc['total_per_thread_buffers']),
        lib.human.bytes2human(mycalc['pf_memory']),
        lib.human.bytes2human(mycalc['max_peak_memory']),
    )
    msg += '* Physical Memory: pm = {}\n'.format(
        lib.human.bytes2human(physical_memory),
    )
    msg += '* Max Used Memory %: mump = mum / pm * 100 = {} / {} * 100 = {}%\n'.format(
        lib.human.bytes2human(mycalc['max_used_memory']),
        lib.human.bytes2human(physical_memory),
        mycalc['pct_max_used_memory'],
    )
    msg += '* Max Possible Memory Usage %: mpmu = ppm / pm * 100 = {} / {} * 100 = {}%\n'.format(
        lib.human.bytes2human(mycalc['max_peak_memory']),
        lib.human.bytes2human(physical_memory),
        mycalc['pct_max_physical_memory'],
    )

    # perfdata
    perfdata += lib.base.get_perfdata('mysql_aria_pagecache_buffer_size', myvar.get('aria_pagecache_buffer_size', 0), 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_innodb_buffer_pool_size', myvar['innodb_buffer_pool_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_innodb_log_buffer_size', myvar['innodb_log_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_join_buffer_size', myvar['join_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_key_buffer_size', myvar['key_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_allowed_packet', myvar['max_allowed_packet'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_connections', myvar['max_connections'], None, None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_heap_table_size', myvar['max_heap_table_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_query_cache_size', myvar.get('query_cache_size', 0), 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_read_buffer_size', myvar['read_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_read_rnd_buffer_size', myvar['read_rnd_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_sort_buffer_size', myvar['sort_buffer_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_thread_stack', myvar['thread_stack'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_tmp_table_size', myvar['tmp_table_size'], 'B', None, None, 0, None)

    perfdata += lib.base.get_perfdata('mysql_max_used_connections', mystat['Max_used_connections'], None, None, None, 0, None)

    perfdata += lib.base.get_perfdata('mysql_physical_memory', physical_memory, 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_peak_memory', mycalc['max_peak_memory'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_tmp_table_size', mycalc['max_tmp_table_size'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_total_per_thread_buffers', mycalc['max_total_per_thread_buffers'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_max_used_memory', mycalc['max_used_memory'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_pct_max_physical_memory', mycalc['pct_max_physical_memory'], '%', None, None, 0, 100)
    perfdata += lib.base.get_perfdata('mysql_pct_max_used_memory', mycalc['pct_max_used_memory'], '%', None, None, 0, 100)
    perfdata += lib.base.get_perfdata('mysql_per_thread_buffers', mycalc['per_thread_buffers'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_server_buffers', mycalc['server_buffers'], 'B', None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_total_per_thread_buffers', mycalc['total_per_thread_buffers'], 'B', None, None, 0, None)

    # over and out
    lib.base.oao(msg, state, perfdata, always_ok=args.ALWAYS_OK)


if __name__ == '__main__':
    try:
        main()
    except Exception:   # pylint: disable=W0703
        lib.base.cu()

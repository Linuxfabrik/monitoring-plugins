#!/usr/bin/env python3
# -*- coding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see LICENSE file.

# https://github.com/Linuxfabrik/monitoring-plugins/blob/main/CONTRIBUTING.md

"""See the check's README for more details.
"""

import argparse  # pylint: disable=C0413
import sys  # pylint: disable=C0413

import lib.base  # pylint: disable=C0413
import lib.db_mysql  # pylint: disable=C0413
import lib.human  # pylint: disable=C0413
from lib.globals import (STATE_OK, STATE_UNKNOWN,  # pylint: disable=C0413
                          STATE_WARN)

__author__ = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2025100601'

DESCRIPTION = """Checks the hit rate for open tables cache lookups in MySQL/MariaDB."""

DEFAULT_DEFAULTS_FILE = '/var/spool/icinga2/.my.cnf'
DEFAULT_DEFAULTS_GROUP = 'client'
DEFAULT_TIMEOUT = 3


def parse_args():
    """Parse command line arguments using argparse.
    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument(
        '-V', '--version',
        action='version',
        version='{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
    )

    parser.add_argument(
        '--always-ok',
        help='Always returns OK.',
        dest='ALWAYS_OK',
        action='store_true',
        default=False,
    )

    parser.add_argument(
        '--defaults-file',
        help='Specifies a cnf file to read parameters like user, host and password from '
             '(instead of specifying them on the command line), '
             'for example `/var/spool/icinga2/.my.cnf`. Default: %(default)s',
        dest='DEFAULTS_FILE',
        default=DEFAULT_DEFAULTS_FILE,
    )

    parser.add_argument(
        '--defaults-group',
        help='Group/section to read from in the cnf file. Default: %(default)s',
        dest='DEFAULTS_GROUP',
        default=DEFAULT_DEFAULTS_GROUP,
    )

    parser.add_argument(
        '--timeout',
        help='Network timeout in seconds. Default: %(default)s (seconds)',
        dest='TIMEOUT',
        type=int,
        default=DEFAULT_TIMEOUT,
    )

    args, _ = parser.parse_known_args()
    return args


def get_vars(conn):
    # Do not implement `get_all_vars()`, just fetch the ones we need for this check.
    # Without the GLOBAL modifier, SHOW VARIABLES displays the values that are used for
    # the current connection to MariaDB.
    sql = """
        show global variables
        where variable_name like 'open_files_limit'
            or variable_name like 'table_open_cache'
            ;
          """
    return lib.base.coe(lib.db_mysql.select(conn, sql))


def get_status(conn):
    # Do not implement `get_all_vars()`, just fetch the ones we need for this check.
    # Without the GLOBAL modifier, SHOW STATUS displays the values that are used for
    # the current connection to MariaDB.
    sql = """
        show global status
        where variable_name like 'Open_tables'
            or variable_name like 'Opened_tables'
            or variable_name like 'Table_open_cache_hits'
            or variable_name like 'Table_open_cache_misses'
            ;
          """
    return lib.base.coe(lib.db_mysql.select(conn, sql))


def main():
    """The main function. Hier spielt die Musik.
    """

    # logic taken from mysqltuner.pl:mysql_stats(), section # Table cache, v1.9.8
    # including variable names

    # parse the command line, exit with UNKNOWN if it fails
    try:
        args = parse_args()
    except SystemExit:
        sys.exit(STATE_UNKNOWN)

    mysql_connection = {
        'defaults_file':  args.DEFAULTS_FILE,
        'defaults_group': args.DEFAULTS_GROUP,
        'timeout':        args.TIMEOUT,
    }
    conn = lib.base.coe(lib.db_mysql.connect(mysql_connection))
    lib.base.coe(lib.db_mysql.check_select_privileges(conn))

    myvar = lib.db_mysql.lod2dict(get_vars(conn))
    mystat = lib.db_mysql.lod2dict(get_status(conn))
    lib.db_mysql.close(conn)

    # init some vars
    state = STATE_OK
    perfdata = ''

    # calculations
    mycalc = {}
    if int(mystat['Opened_tables']) > 0:
        if mystat.get('Table_open_cache_hits', None) is None:
            mycalc['table_cache_hit_rate'] = round(int(mystat['Open_tables']) / int(mystat['Opened_tables']) * 100, 1)
        else:
            mycalc['table_cache_hit_rate'] = round(int(mystat['Table_open_cache_hits']) / (int(mystat['Table_open_cache_hits']) + int(mystat['Table_open_cache_misses'])) * 100, 1)
    else:
        mycalc['table_cache_hit_rate'] = 100

    # Table cache
    if int(mystat['Open_tables']) > 0:
        if mystat.get('Table_open_cache_hits', None) is None:
            msg = '{}% table cache hit rate ({} hits / {} requests)'.format(
                mycalc['table_cache_hit_rate'],
                lib.human.number2human(mystat['Open_tables']),
                lib.human.number2human(mystat['Opened_tables']),
            )
        else:
            msg = '{}% table cache hit rate ({} hits / {} requests)'.format(
                mycalc['table_cache_hit_rate'],
                lib.human.number2human(mystat['Table_open_cache_hits']),
                lib.human.number2human(int(mystat['Table_open_cache_hits']) + int(mystat['Table_open_cache_misses'])),
            )
            perfdata += lib.base.get_perfdata('mysql_table_open_cache_hits', mystat['Table_open_cache_hits'], 'c', None, None, 0, None)
            perfdata += lib.base.get_perfdata('mysql_table_open_cache_misses', mystat['Table_open_cache_misses'], 'c', None, None, 0, None)

        if mycalc['table_cache_hit_rate'] < 20:
            state = STATE_WARN
            msg += '{}. Set table_open_cache > {}. '.format(
                lib.base.state2str(state, prefix=' '),
                myvar['table_open_cache'],
            )
            msg += 'Beware that open_files_limit ({}) should be greater than table_open_cache ({}). '.format(
                myvar['open_files_limit'],
                myvar['table_open_cache'],
            )
            msg += 'Increase table_open_cache gradually to avoid file descriptor limits. '
            msg += 'Make sure that your operating system can cope with the number of open file '
            msg += 'descriptors required by the table_open_cache setting. If table_open_cache is '
            msg += 'set too high, the DB may start to refuse connections as the operating system '
            msg += 'runs out of file descriptors. Also note that the MyISAM (and Aria?) storage '
            msg += 'engines need two file descriptors per open table.'
    else:
        msg = 'Everything is ok.'

    perfdata += lib.base.get_perfdata('mysql_open_files_limit', myvar['open_files_limit'], None, None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_table_open_cache', myvar['table_open_cache'], None, None, None, 0, None)

    perfdata += lib.base.get_perfdata('mysql_open_tables', mystat['Open_tables'], None, None, None, 0, None)
    perfdata += lib.base.get_perfdata('mysql_opened_tables', mystat['Opened_tables'], None, None, None, 0, None)

    perfdata += lib.base.get_perfdata('mysql_table_cache_hit_rate', mycalc['table_cache_hit_rate'], '%', None, None, 0, 100)

    # over and out
    lib.base.oao(msg, state, perfdata, always_ok=args.ALWAYS_OK)


if __name__ == '__main__':
    try:
        main()
    except Exception:   # pylint: disable=W0703
        lib.base.cu()
